Guides | Crawlee
Skip to main content

Crawlee
Crawlee
Docs
Examples
API
Changelog
3.5
Next
Next
3.5
3.5
3.4
3.4
3.3
3.3
3.2
3.2
3.1
3.1
3.0
3.0
2.2
2.2
1.3
1.3


GitHub
Discord
SearchâŒ˜K
Search
Search
âŒ˜K

Crawlee
Crawlee
Quick Start
Quick Start
IntroductionSetting upFirst crawlerAdding more URLsReal-world projectCrawlingScrapingSaving dataRefactoring
Introduction

Setting up
Setting up
First crawler
First crawler
Adding more URLs
Adding more URLs
Real-world project
Real-world project
Crawling
Crawling
Scraping
Scraping
Saving data
Saving data
Refactoring
Refactoring
GuidesRequest StorageResult StorageConfigurationCheerioCrawlerJavaScript renderingProxy ManagementSession ManagementScaling our crawlersAvoid getting blockedJSDOMCrawlerGot ScrapingTypeScript ProjectsRunning in DockerApify Platform
Guides

Request Storage
Request Storage
Result Storage
Result Storage
Configuration
Configuration
CheerioCrawler
CheerioCrawler
JavaScript rendering
JavaScript rendering
Proxy Management
Proxy Management
Session Management
Session Management
Scaling our crawlers
Scaling our crawlers
Avoid getting blocked
Avoid getting blocked
JSDOMCrawler
JSDOMCrawler
Got Scraping
Got Scraping
TypeScript Projects
TypeScript Projects
Running in Docker
Running in Docker
Apify Platform
Apify Platform
Examples
Examples

Upgrading
Upgrading




Guides
Guides
Version: 3.5
Guides
ğŸ“„ï¸ Request StorageHow to store the requests your crawler will go through
ğŸ“„ï¸ Request Storage
How to store the requests your crawler will go through
ğŸ“„ï¸ Result StorageWhere are you going to store all of that juicy scraped data?!
ğŸ“„ï¸ Result Storage
Where are you going to store all of that juicy scraped data?!
ğŸ“„ï¸ ConfigurationConfiguring Crawlee parameters
ğŸ“„ï¸ Configuration
Configuring Crawlee parameters
ğŸ“„ï¸ CheerioCrawlerYour first steps into the world of scraping with Crawlee
ğŸ“„ï¸ CheerioCrawler
Your first steps into the world of scraping with Crawlee
ğŸ“„ï¸ JavaScript renderingYour first steps into the world of scraping with Crawlee
ğŸ“„ï¸ JavaScript rendering
Your first steps into the world of scraping with Crawlee
ğŸ“„ï¸ Proxy ManagementUsing proxies to get around those annoying IP-blocks
ğŸ“„ï¸ Proxy Management
Using proxies to get around those annoying IP-blocks
ğŸ“„ï¸ Session ManagementHow to manage your cookies, proxy IP rotations and more
ğŸ“„ï¸ Session Management
How to manage your cookies, proxy IP rotations and more
ğŸ“„ï¸ Scaling our crawlersTo infinity and beyond! ...within limits
ğŸ“„ï¸ Scaling our crawlers
To infinity and beyond! ...within limits
ğŸ“„ï¸ Avoid getting blockedHow to avoid getting blocked when scraping
ğŸ“„ï¸ Avoid getting blocked
How to avoid getting blocked when scraping
ğŸ“„ï¸ JSDOMCrawlerYour first steps into the world of scraping with Crawlee
ğŸ“„ï¸ JSDOMCrawler
Your first steps into the world of scraping with Crawlee
ğŸ“„ï¸ Got ScrapingBlazing fast cURL alternative for modern web scraping
ğŸ“„ï¸ Got Scraping
Blazing fast cURL alternative for modern web scraping
ğŸ“„ï¸ TypeScript ProjectsStricter, safer, and better development experience
ğŸ“„ï¸ TypeScript Projects
Stricter, safer, and better development experience
ğŸ“„ï¸ Running in DockerExample Docker images to run your crawlers
ğŸ“„ï¸ Running in Docker
Example Docker images to run your crawlers
ğŸ“„ï¸ Apify PlatformApify platform - large-scale and high-performance web scraping
ğŸ“„ï¸ Apify Platform
Apify platform - large-scale and high-performance web scraping
PreviousRefactoring
NextRequest Storage
Guides
Guides
Examples
Examples
API reference
API reference
Upgrading to v3
Upgrading to v3
Discord
Discord
Stack Overflow
Stack Overflow
Twitter
Twitter
Apify Platform
Apify Platform
Docusaurus
Docusaurus
GitHub
GitHub
Crawlee is free and open source
Built by
Built by
