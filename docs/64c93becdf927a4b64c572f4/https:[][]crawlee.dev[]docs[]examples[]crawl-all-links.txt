Crawl all links on a website | Crawlee
Skip to main content

Crawlee
Crawlee
Docs
Examples
API
Changelog
3.5
Next
Next
3.5
3.5
3.4
3.4
3.3
3.3
3.2
3.2
3.1
3.1
3.0
3.0
2.2
2.2
1.3
1.3


GitHub
Discord
Search⌘K
Search
Search
⌘K

Crawlee
Crawlee
Quick Start
Quick Start
IntroductionSetting upFirst crawlerAdding more URLsReal-world projectCrawlingScrapingSaving dataRefactoring
Introduction

Setting up
Setting up
First crawler
First crawler
Adding more URLs
Adding more URLs
Real-world project
Real-world project
Crawling
Crawling
Scraping
Scraping
Saving data
Saving data
Refactoring
Refactoring
Guides
Guides

ExamplesAccept user inputAdd data to datasetBasic crawlerCheerio crawlerCrawl all links on a websiteCrawl multiple URLsCrawl a website with relative linksCrawl a single URLCrawl a sitemapCrawl some links on a websiteUsing puppeteer-extra and playwright-extraExport entire dataset to one fileFormsHTTP crawlerJSDOM crawlerDataset Map and Reduce methodsPlaywright crawlerUsing Firefox browser with Playwright crawlerCapture a screenshot using PuppeteerPuppeteer crawlerPuppeteer recursive crawlSkipping navigations for certain requests
Examples

Accept user input
Accept user input
Add data to dataset
Add data to dataset
Basic crawler
Basic crawler
Cheerio crawler
Cheerio crawler
Crawl all links on a website
Crawl all links on a website
Crawl multiple URLs
Crawl multiple URLs
Crawl a website with relative links
Crawl a website with relative links
Crawl a single URL
Crawl a single URL
Crawl a sitemap
Crawl a sitemap
Crawl some links on a website
Crawl some links on a website
Using puppeteer-extra and playwright-extra
Using puppeteer-extra and playwright-extra
Export entire dataset to one file
Export entire dataset to one file
Forms
Forms
HTTP crawler
HTTP crawler
JSDOM crawler
JSDOM crawler
Dataset Map and Reduce methods
Dataset Map and Reduce methods
Playwright crawler
Playwright crawler
Using Firefox browser with Playwright crawler
Using Firefox browser with Playwright crawler
Capture a screenshot using Puppeteer
Capture a screenshot using Puppeteer
Puppeteer crawler
Puppeteer crawler
Puppeteer recursive crawl
Puppeteer recursive crawl
Skipping navigations for certain requests
Skipping navigations for certain requests
Upgrading
Upgrading




Examples
Examples
Examples
Crawl all links on a website
Crawl all links on a website
Version: 3.5
Crawl all links on a website
This example uses the enqueueLinks() method to add new links to the RequestQueue
as the crawler navigates from page to page.

If no options are given, by default the method will only add links that are under the same subdomain. This behavior can be controlled with the strategy
option. You can find more info about this option in the Crawl relative links examples.
strategy
Crawl relative links
Cheerio Crawler
Puppeteer Crawler
Playwright Crawler
import { CheerioCrawler } from 'crawlee';
import
 
{
 
CheerioCrawler
 
}
 
from
 
'crawlee'
;



const crawler = new CheerioCrawler({

const
 crawler 
=
 
new
 
CheerioCrawler
(
{

    async requestHandler({ request, enqueueLinks, log }) {
    
async
 
requestHandler
(
{
 request
,
 enqueueLinks
,
 log 
}
)
 
{

        log.info(request.url);
        log
.
info
(
request
.
url
)
;

        // Add all links from page to RequestQueue
        
// Add all links from page to RequestQueue

        await enqueueLinks();
        
await
 
enqueueLinks
(
)
;

    },
    
}
,

    maxRequestsPerCrawl: 10, // Limitation for only 10 requests (do not use if you want to crawl all links)
    
maxRequestsPerCrawl
:
 
10
,
 
// Limitation for only 10 requests (do not use if you want to crawl all links)

});

}
)
;



// Run the crawler with initial request

// Run the crawler with initial request

await crawler.run(['https://crawlee.dev']);

await
 crawler
.
run
(
[
'https://crawlee.dev'
]
)
;




To run this example on the Apify Platform, select the apify/actor-node-puppeteer-chrome image for your Dockerfile.
import { PuppeteerCrawler } from 'crawlee';
import
 
{
 
PuppeteerCrawler
 
}
 
from
 
'crawlee'
;



const crawler = new PuppeteerCrawler({

const
 crawler 
=
 
new
 
PuppeteerCrawler
(
{

    async requestHandler({ request, enqueueLinks, log }) {
    
async
 
requestHandler
(
{
 request
,
 enqueueLinks
,
 log 
}
)
 
{

        log.info(request.url);
        log
.
info
(
request
.
url
)
;

        // Add all links from page to RequestQueue
        
// Add all links from page to RequestQueue

        await enqueueLinks();
        
await
 
enqueueLinks
(
)
;

    },
    
}
,

    maxRequestsPerCrawl: 10, // Limitation for only 10 requests (do not use if you want to crawl all links)
    
maxRequestsPerCrawl
:
 
10
,
 
// Limitation for only 10 requests (do not use if you want to crawl all links)

});

}
)
;



// Run the crawler with initial request

// Run the crawler with initial request

await crawler.run(['https://crawlee.dev']);

await
 crawler
.
run
(
[
'https://crawlee.dev'
]
)
;



To run this example on the Apify Platform, select the apify/actor-node-playwright-chrome image for your Dockerfile.
import { PlaywrightCrawler } from 'crawlee';
import
 
{
 
PlaywrightCrawler
 
}
 
from
 
'crawlee'
;



const crawler = new PlaywrightCrawler({

const
 crawler 
=
 
new
 
PlaywrightCrawler
(
{

    async requestHandler({ request, enqueueLinks, log }) {
    
async
 
requestHandler
(
{
 request
,
 enqueueLinks
,
 log 
}
)
 
{

        log.info(request.url);
        log
.
info
(
request
.
url
)
;

        // Add all links from page to RequestQueue
        
// Add all links from page to RequestQueue

        await enqueueLinks();
        
await
 
enqueueLinks
(
)
;

    },
    
}
,

    maxRequestsPerCrawl: 10, // Limitation for only 10 requests (do not use if you want to crawl all links)
    
maxRequestsPerCrawl
:
 
10
,
 
// Limitation for only 10 requests (do not use if you want to crawl all links)

});

}
)
;



// Run the crawler with initial request

// Run the crawler with initial request

await crawler.run(['https://crawlee.dev']);

await
 crawler
.
run
(
[
'https://crawlee.dev'
]
)
;


Last updated on Jul 31, 2023 by renovate[bot]
Jul 31, 2023
renovate[bot]
PreviousCheerio crawler
NextCrawl multiple URLs
Guides
Guides
Examples
Examples
API reference
API reference
Upgrading to v3
Upgrading to v3
Discord
Discord
Stack Overflow
Stack Overflow
Twitter
Twitter
Apify Platform
Apify Platform
Docusaurus
Docusaurus
GitHub
GitHub
Crawlee is free and open source
Built by
Built by
