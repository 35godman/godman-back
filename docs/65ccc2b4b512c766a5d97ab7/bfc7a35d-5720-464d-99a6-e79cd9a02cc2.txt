Opens in a new window Opens an external website Opens an external website in a
new window
<!---->Close this dialog<!---->
This website utilizes technologies such as cookies to enable essential site
functionality, as well as for analytics, personalization, and targeted
advertising purposes. To learn more, view the following link:



<!---->Close Cookie Preferences<!---->


Product
Solutions
Resources
Company



BUILD KNOWLEDGEABLE AI

Pinecone serverless lets you deliver remarkable GenAI applications faster, at up
to 50x lower cost.


[/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2FHomepage-Hero-BG.01eaa1e4.png&w=3840&q=100]

Pinecone is the that helps power AI for the world’s

Frontier Meds logo
[/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Ffrontier-medicines-dark.7bec6bec.png&w=384&q=75]


START AND SCALE SEAMLESSLY

StartSearchScale

Create an account and your first index in 30 seconds, then upload a few vector
embeddings from any model… or a few billion.

Perform low-latency vector search to retrieve relevant data for search, ,
recommendation, detection, and other applications.

Pinecone is serverless so you never have to worry about managing or scaling the
database.

PythonNodecURL

from pinecone import Pinecone, ServerlessSpec

# Create a serverless index
# "dimension" needs to match the dimensions of the vectors you upsert
pc = Pinecone(api_key="YOUR_API_KEY")

pc.create_index(name="products", dimension=1536, 
    spec=ServerlessSpec(cloud='aws', region='us-west-2') 
)

# Target the index
index = pc.Index("products")

# Mock vector and metadata objects (you would bring your own)
vector = [0.010, 2.34,...] # len(vector) = 1536
metadata = {"id": 3056, "description": "Networked neural adapter"}

# Upsert your vector(s)
index.upsert(
  vectors=[
    {"id": "some_id", "values": vector, "metadata": metadata}
  ]
) 





MORE RELEVANT RESULTS MAKE BETTER APPLICATIONS


FILTER BY
METADATA

Combine vector search with familiar to get just the results you want.


FIND
CONTEXT

Fast and over all your data.


UPDATE IN
REAL TIME

As your data changes, the Pinecone index is updated in realtime to provide the
freshest results.


MAKE (THE RIGHT)
KEYWORDS MATTER

Combine vector search with keyword boosting for the best of both worlds ().


UP TO 50X

lower cost


96%

recall*


51MS

query latency (p95)*

benchmark graphic
[/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Flatency-serverless-benchmark-chart.30a6b619.png&w=3840&q=75]
*Performance with MSMarco V2 dataset of 138M embeddings (1536 dimensions)


PART OF THE DEVELOPER-FAVORITE AI STACK

Use Pinecone with your favorite cloud provider, data sources, models,
frameworks, and more.

Amazon Web Services
[/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Faws-logo.c56d2f52.png&w=3840&q=100]
Microsoft Azure
[/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fazure-logo.77825207.png&w=3840&q=100]
GCP
[/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fgoogle-cloud.0c11b1e3.png&w=3840&q=100]
Anyscale [/_next/static/media/anyscale-logo.d7b077c8.svg]
OpenAI [/_next/static/media/openai-logo.2b7cea66.svg]
Cohere
[/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fcohere.7610df1a.png&w=3840&q=100]
Pulumi [/_next/static/media/pulumi-logo.151d5c0d.svg]
Hugging Face [/_next/static/media/huggingface_logo.4539e1ae.svg]
Vercel [/_next/static/media/vercel_logo.bab0aeaf.svg]
Langchain
[/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Flangchain-logo.9dc25b2c.png&w=3840&q=100]
Llama Index
[/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fllama-index.874d0715.png&w=3840&q=100]
Haystack [/_next/static/media/haystack-logo-cropped.25acbae9.svg]
Databricks
[/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdatabricks-logo.e1af4cd3.png&w=3840&q=100]
Snowflake [/_next/static/media/snowflake-logo.7a9dd7a5.svg]
Confluent [/_next/static/media/confluent-logo.ee58556b.svg]
Airbyte
[/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fairbyte-logo.b3f0d416.png&w=3840&q=100]
New Relic [/_next/static/media/new-relic.ad20d85a.svg]
Datadog
[/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fdatadog.fdc2fd0e.png&w=3840&q=100]
SearchGenerateFine Tune

Data source

Embedding model

Pinecone Vector Database

Search application


JOIN THE MOVEMENT

Join a growing community of 400,000+ ambitious developers building the next
generation of applications with Pinecone.

Pinecone event
[/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fpinecone-event.ec594ac7.png&w=3840&q=75]

Events

Learn and connect with your peers, in person and online.

Docs

Take advantage of our developer-friendly docs to get going in minutes.

Forum

Share your questions, and answers in the support forum.

Notion logo [/_next/static/media/notion-logo.90564ffe.svg]

Billions

of records in Pinecone

To make our newest Notion AI products available to tens of millions of users
worldwide we needed to support RAG over billions of documents while meeting
strict performance, security, cost, and operational requirements. This simply
wouldn’t be possible without Pinecone.

Akshay Kothari
[/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fakshay-kothari.cbe8e397.png&w=384&q=75]

Akshay Kothari

Co-Founder, Notion


SECURE AND ENTERPRISE-READY

Meet security and operational requirements to bring AI products to market
faster.


SECURE

Control your data and know it’s safe. Pinecone is SOC 2 and HIPAA certified.


RELIABLE

Powering mission-critical applications of all sizes, with support SLAs and
observability.


CLOUD-NATIVE

Fully managed in the cloud of your choice. Also available via marketplaces: AWS,
Azure, GCP.


START BUILDING KNOWLEDGEABLE AI NOW

Create your first index for free, then upgrade and when you're ready to scale,
or .


Product

Solutions

Resources

Company

Legal


© Pinecone Systems, Inc. | San Francisco, CA

Pinecone is a registered trademark of Pinecone Systems, Inc.