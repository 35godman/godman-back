Opens in a new window Opens an external website Opens an external website in a
new window
<!---->Close this dialog<!---->
This website utilizes technologies such as cookies to enable essential site
functionality, as well as for analytics, personalization, and targeted
advertising purposes. To learn more, view the following link:



<!---->Close Cookie Preferences<!---->


v1v2

--------------------------------------------------------------------------------

Guides

v2

Ctrl+K
Performance tuning
All
Guides
Reference
Pages

START TYPING TO SEARCH…


GETTING STARTED

 * 
 * 
 * 
 * 
 * 


ORGANIZATIONS

 * 
 * * 
   * 
   * 
   * 
   * 
 * * 
   * 
   * 


PROJECTS

 * 
 * 
 * 
 * 
 * 


INDEXES

 * 
 * 
 * 
 * 
 * 
 * 
 * 


DATA

 * 
 * 
 * 
 * 
 * 
 * 
 * 
 * 
 * 
 * * 
   * 
   * 
   * 
 * * 
   * 


OPERATIONS

 * 
 * 
 * 
 * 
 * 


INTEGRATIONS

 * 
 * 
 * 
 * 
 * 
 * 
 * 
 * 
 * 
 * 
 * 
 * 


REFERENCE

 * 
 * 
 * 
 * 
 * 
 * 


SUPPORT

 * 
 * 
 * 


PERFORMANCE TUNING



This section provides some tips for getting the best performance out of
Pinecone.


BASIC PERFORMANCE CHECKLIST

 * Switch to a cloud environment. For example: EC2, GCE, , , or . If you
   experience slow uploads or high query latencies, it might be because you are
   accessing Pinecone from your home network.
 * Deploy your application and your Pinecone service in the same region. if you
   need a dedicated deployment.
 * Reuse connections. We recommend you reuse the same pinecone.Pinecone.Index()
   instance when you are upserting
   vectors into, and querying, the same index.
 * Operate within known .


INCREASING THROUGHPUT


BATCH UPSERTS

When upserting larger amounts of data, of 100-500 vectors over multiple upsert
requests. Batching significantly reduces the time it takes to process data.


SEND UPSERTS IN PARALLEL

Pinecone is thread-safe, so you can to help increase throughput. You can read
more about on our blog.


> ℹ️
> 
> NOTE
> 
> For serverless indexes, reads and writes follow independent paths, so you can
> can send multiple read and write requests in parallel to improve throughput.
> 
> For pod-based indexes, multiple reads can be performed in parallel, and
> multiple writes can be performed in parallel, but multiple reads and writes
> cannot be performed in parallel. Therefore, write batches may affect query
> latency, and read batches may affect write throughput.


SCALE POD-BASED INDEXES

To increase throughput (QPS) for pod-based indexes, increase the number of
replicas for your index. See the for more details.


> ℹ️
> 
> NOTE
> 
> With , you don't configure any compute or storage resources, and you don't
> need to manually scale resources to increase throughput. Instead, serverless
> indexes scale automatically based on usage.

Example

The following example increases the number of replicas for example-index to 4.

PythonJavaScriptcurl
from pinecone import Pinecone

pc = Pinecone(api_key="YOUR_API_KEY")

pc.configure_index("example-index", replicas=4)


import { Pinecone } from '@pinecone-database/pinecone'

const pc = new Pinecone({
  apiKey: 'YOUR_API_KEY'
});

await pc.configureIndex('example-index', { replicas: 4 });


PINECONE_API_KEY = "YOUR_API_KEY"

curl -s -X PATCH "https://api.pinecone.io/indexes/example-index" \
  -H "Content-Type: application/json" \
  -H "Api-Key: $PINECONE_API_KEY" \
  -d '{
         "replicas": 4
      }'


See the for more details.


DECREASING LATENCY


USE NAMESPACES

When you use namespaces to partition records within a single index, you can
limit queries to specific namespaces to reduces the number of records scanned.
For more details, see .


USE METADATA FILTERING

When you attach metadata key-value pairs to records, you can filter queries to
retrieve only records that match the metadata filter. For more details, see .


> ⚠️
> 
> WARNING
> 
> For p2 pod-based indexes, metadata filters can increase query latency.


AVOID NETWORK CALLS TO FETCH INDEX HOSTS

When you target an index, the Python and Node.js clients make a network call to
fetch the host where the index is deployed. In a production situation, you can
avoid this additional round trip by specifying the host of the index as follows:

Python
from pinecone import Pinecone

pc = Pinecone(api_key="YOUR_API_KEY")
index = pc.Index(host="INDEX_HOST")


You can get the host of an index using the Pinecone cosole or using the
describe_index operation. For more details, see .

Updated 20 days ago

--------------------------------------------------------------------------------


Did this page help you?
Yes
No
 * 
 * * 
   * * 
     * 
     * 
   * * 
     * 
     * 







Pinecone [https://pinecone.io/images/pinecone-white.svg]
 * 
 * 
 * 
 * 
 * 
 * 

© Pinecone Systems, Inc. | San Francisco, CA | | | | | |

Pinecone is a registered trademark of Pinecone Systems, Inc.


