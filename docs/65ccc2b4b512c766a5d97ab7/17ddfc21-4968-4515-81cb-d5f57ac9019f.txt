Opens in a new window Opens an external website Opens an external website in a
new window
<!---->Close this dialog<!---->
This website utilizes technologies such as cookies to enable essential site
functionality, as well as for analytics, personalization, and targeted
advertising purposes. To learn more, view the following link:



<!---->Close Cookie Preferences<!---->


Product
Solutions
Resources
Company



OPTIONS FOR SOLVING HALLUCINATIONS IN GENERATIVE AI

Aug 21, 2023

Author
[/_next/image/?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fvr8gru94%2Fproduction%2F6d0c22de734e65c089fcee0d2e924af2e8e4301e-484x444.png&w=3840&q=100]

Senior Product Marketing Manager

--------------------------------------------------------------------------------

Jump to section

--------------------------------------------------------------------------------


GEN AI CAN DELIVER TRILLIONS - ARE YOU READY TO CAPTURE IT?

If you’re under pressure to start a Generative AI product strategy for your
company, you are not alone. A of 400 senior AI professionals at organizations
with annual revenue above $3 billion shows that more than 60% of them are likely
to adopt Generative AI in the next 12 months, while 45% of the respondents have
already started their Generative AI experiment.

At Pinecone, we’re seeing an explosion of interest from engineering leaders at
large enterprises. They come to us with similar questions: We have an ambitious
AI plan; where should we get started, and how can we get it right?

This enthusiasm and sense of urgency come from the significant business impact
Generative AI could bring. Mckinsey that Generative AI has the potential to
contribute approximately $2.6 trillion to $4.4 trillion yearly across 63
different use cases. In the banking sector alone, its full implementation across
use cases could generate an extra $200 billion to $340 billion annually.

We are developing a series guiding you to navigate this exciting but noisy space
and help your company capture the full potential of AI. Today we’ll be focused
on addressing in Gen AI applications.

stands out as a widely-adopted approach to address Gen AI hallucination. In this
article, we’ll explain what AI hallucination is, the main solutions for this
problem, and why RAG is the preferred approach in terms of scalability,
cost-efficacy, and performance.


HALLUCINATION - A MAJOR CHALLENGE IN BUILDING GENERATIVE AI APPLICATIONS

The excitement around Generative has propelled the wide adoption of Large
Language Models (LLMs). While LLMs like Meta’s Llama2 have made building AI
applications easier than ever, they also come with many issues. And one of the
most discussed concerns is AI hallucination. Hallucination is when LLMs make up
answers but make them sound factual. Let’s take a look at the example below.

Let’s say a user comes to your AI Chatbot and wants to figure out how to turn
off the automatic reverse braking on the Volvo XC60. Your chatbot generates the
answer below:

Hallucinated Generative Chat
[https://cdn.sanity.io/images/vr8gru94/production/40bc19703de4b9c36170e43fc4838538d2018c28-1600x334.png]
Hallucinated Generative Chat

It may sound plausible with accurate grammar and seemingly reasonable steps, but
it’s a total hallucination. What causes AI applications to hallucinate?


REASONS FOR AI HALLUCINATION

There are two main reasons for hallucination:


LLMS ARE TRAINED LARGELY FROM INFORMATION SCRAPED FROM THE INTERNET

They don’t have access to a much larger corpus of information that is
proprietary and stored in corporate data warehouses. Because they are trained
largely from information scraped from the Internet, which unfortunately also
encodes all kinds of dangerous misinformation, they can produce wrong and even
harmful outputs. Even though the teams behind those LLMs like Claude highlight
their effort in red teaming, this remains a huge problem for most, if not all,
LLMs today.


LLMS SUFFER FROM KNOWLEDGE CUTOFF

Training LLMs is time-consuming and extremely expensive. OpenAI’s Sam Altman
estimated it cost around $100 million to train the foundation model behind
ChatGPT. But they become quickly out-of-date with respect to any recent
information. This is called knowledge cutoff, meaning that LLMs are unaware of
any post-training event.

For example, ChatGPT/GPT-4 is unable to provide answers after September 2021. If
the answer you're looking for requires up-to-date information, proprietary
company data, or even the current weather in New York, you're likely to get a
hallucination without additional and timely context.

Hallucination is concerning because the LLMs generating them don't know they're
hallucinating. They are designed to respond with convincing-sounding text
output, so it requires a human expert to pay attention to notice hallucinations
at the moment. If your model is talking directly to your customers and
hallucinating, it can lead to lost customer trust and a damaged brand.

The factually wrong answers could be very dangerous in certain cases, like
giving incorrect instructions about how to turn off a certain braking mode in
your car.


MAIN APPROACHES TO REDUCE HALLUCINATION

There are a few main approaches to building better AI products, including 1)
training your own model, 2) fine tuning, 3) prompt engineering, and 4) Retrieval
Augmented Generation. Let’s take a look at those options and see why RAG is the
most popular option among companies. We’ll evaluate each option on their
scalability (cost and complexity) and performance.


TRAIN YOUR OWN FOUNDATIONAL MODEL

Many large enterprises are investigating training their own foundation models on
their own proprietary, domain-specific data.

To train a foundational model, you need to jump through several hoops, including
acquiring a diverse dataset for training the foundation model on various tasks,
preparing the dataset, configuring training parameters, algorithm architecture,
computational resources, and more before you can deploy the model for user
access.

Steps to train your own foundation model
[https://cdn.sanity.io/images/vr8gru94/production/05758927a638015e426400bc4f775059139b1692-1932x2212.png]
Steps to train your own foundation model

This is the most complex, costly, and time-consuming approach of all. You’ll
need 1) expertise - a top-notch team including machine learning experts and
system engineers, 2) a significant amount of computing resources, and 3) massive
labeled data sets. While it can improve accuracy with training in
domain-specific data, it doesn’t solve the problem that a model won’t have
access to recent or real-time data.


FINE TUNING

Fine-tuning is the process of providing additional training to a model with a
smaller task-specific dataset.

For example, if you’d like to build a sentiment analysis product using fine
tuning, you’ll need to choose a pre-trained LLM and fine tune it on an
additional dataset with financial news and market reports etc.

Steps to fine tune a foundation model
[https://cdn.sanity.io/images/vr8gru94/production/d295e81220f41ba281ea49f5c1385a41b036bad7-2400x2246.png]
Steps to fine tune a foundation model

Although it’s less resource-intensive than training your own model, it’s still
complex and costly. You need to repeatedly invest significant time, money, and
effort in labeling tasks, while also continuously overseeing quality changes,
accuracy fluctuations, and shifts in data distribution. If your data evolves,
even a fine-tuned model can’t guarantee accuracy. It doesn’t give your products
long-term memory; you have to update your model constantly.


PROMPT ENGINEERING

Prompt engineering refers to experimenting with your instructions to the AI
model so it can generate optimal results.

This is the easiest and least costly approach, as you can update your prompts
easily with just a few lines of code, but it delivers the least improvement in
terms of addressing hallucinations. LLMs accept not just prompts but also
context, which is additional relevant information provided to the model for
consideration when generating the answer. Prompt engineering doesn’t provide any
meaningful new context.


WHY RAG IS THE PREFERRED APPROACH TO DELIVER ENTERPRISE-GRADE GEN AI PRODUCTS

Retrieval Augmented Generation refers to the process when your Gen AI
application fetches specific and relevant context and provides it to the LLM at
generation time. The image below shows how RAG solves hallucination in the Volvo
case.

Retrieval Augmented Generation
[https://cdn.sanity.io/images/vr8gru94/production/de1fff6bd415cee52a784c1133bb43f1f3d12e3e-1600x573.png]
Retrieval Augmented Generation
 1. Query: A user sends a query to the chatbot.
 2. Contextual search: This is the step where the query gets additional context
    with your Gen AI application searching and retrieving contextual information
    from external data sources.
 3. Inference: The LLM receives the original query sent by the user with the
    additional context. This significantly increases the model’s accuracy
    because it can access factual data.
 4. Response: The LLM sends the response back to the chatbot with factually
    correct information.

With the RAG model, our user can finally get the right answer to turn off the
automatic reverse braking on the Volvo xc60.


UNDERSTANDING EMBEDDINGS AND VECTOR DATABASE IN RAG

The above flow shows the high-level framework of RAG. To fully understand its
implementation details, you need to know . Semantic search, unlike keyword-based
search, focuses on the meaning of the search query. It finds relevant results
with similar meanings even if the exact words don’t match.

To do a semantic search, you need to convert the user’s query into , a type of
numeric data representation that carries within it semantic information that’s
critical for the AI to gain understanding and maintain a long-term memory they
can draw upon when executing complex tasks. These embeddings are then sent to
the that stores the embeddings of your proprietary data. The database conducts a
"nearest neighbor" search, identifying vectors that most closely match the
user's intent. Once the vector database retrieves the nearest vectors, your
application supplies them to the LLM through its , guiding it to execute its
generative response.


ACHIEVE PERFORMANCE, COST EFFICIENCY, AND SCALABILITY WITH RAG

Semantic Search and RAG provide dramatically more relevant search results than a
keyword search. As a result, most companies are moving to this approach when
they build their GenAI applications. Together with LLMs, they are one of the two
key technologies for building great generative AI applications today.

Pros and cons for main solutions
[https://cdn.sanity.io/images/vr8gru94/production/1e73bac18786d93ea75ce57640739b10381921b4-1600x750.png]
Pros and cons for main solutions

Compared to other approaches, RAG is much easier to implement because it doesn't
require machine learning experts. Your application developers can figure it out
relatively quickly and implement it in your GenAI apps. If you’re , you can get
started in seconds.

RAG allows you to generate more contextually relevant responses with improved
accuracy, especially for intricate queries demanding a profound knowledge of the
subject. Additionally, RAG can be customized for particular sectors, making it a
versatile instrument for a range of uses in finance, e-commerce, software
development, and more. Unlike pre-trained models, RAG can leverage inherent
knowledge that can be readily adjusted or even augmented on the go. This
empowers researchers and engineers to manage recent knowledge without the need
to retrain the entire model, saving time and computational resources.


WHAT’S NEXT?

Understanding that RAG is the most cost-effective approach to improving your
Generative AI performance is only the start. We’ll dive into more topics as you
start your Generative AI journey. Stay tuned.

If you want to catch up in the Generative AI competition, don’t wait around. and
learn how Pinecone can help you deliver better results.




Share via:


FURTHER READING


Author
[/_next/image/?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fvr8gru94%2Fproduction%2F6d0c22de734e65c089fcee0d2e924af2e8e4301e-484x444.png&w=3840&q=100]

Senior Product Marketing Manager

--------------------------------------------------------------------------------

Jump to section
 * 
 * 
 * 
 * 
 * 
 * 

Share via:


Product

Solutions

Resources

Company

Legal


© Pinecone Systems, Inc. | San Francisco, CA

Pinecone is a registered trademark of Pinecone Systems, Inc.

[/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fpopup-bg.197eeb2c.png&w=3840&q=100]


INTRODUCING — PINECONE SERVERLESS

Build knowledgeable AI at up to 50x lower cost. No need to manage
infrastructure. Get started with $100 in usage credits.



DON'T MISS THE NEXT ONE...



Get an email the next time we publish an article about machine learning and
similarity search.

Get Updates