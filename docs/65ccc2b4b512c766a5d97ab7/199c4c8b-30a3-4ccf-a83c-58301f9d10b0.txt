Opens in a new window Opens an external website Opens an external website in a
new window
<!---->Close this dialog<!---->
This website utilizes technologies such as cookies to enable essential site
functionality, as well as for analytics, personalization, and targeted
advertising purposes. To learn more, view the following link:



<!---->Close Cookie Preferences<!---->


Product
Solutions
Resources
Company



HOW MACHINE LEARNING IS ACCELERATING LIFE SCIENCES

Jun 30, 2023

Author
[/_next/image/?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fvr8gru94%2Fproduction%2Fa800979e65dc4e374b59c6010e78b8851708e013-475x512.png&w=3840&q=100]

Diego Lopez Yse

Data Scientist

--------------------------------------------------------------------------------

Jump to section

--------------------------------------------------------------------------------

Moore’s Law predicts that computing will dramatically increase in power and
decrease in relative cost at an . Although this principle mainly applies to
computing hardware, DNA sequencing cost has followed a similar pattern for many
years, approximately halving every two years. But since January 2008 there has
been a break in that trend, with sequencing costs dropping much faster than the
cost of processing data on computers. The cost of getting DNA data has never
been cheaper, and it will continue to decrease.

Cost per human genome
[https://cdn.sanity.io/images/vr8gru94/production/7e40cbb904aaf2c6cb8b0d2b0bb848f837cb6ebf-1000x563.png]
The sudden and profound out-pacing of Moore’s Law beginning in January 2008.
Source:

The result of this is that a data tsunami is coming into Life Sciences, with
estimations that over will have their genome sequenced in a healthcare context
by 2025, and that between 2 and 40 exabytes of data within the next decade.

Number of datasets
[https://cdn.sanity.io/images/vr8gru94/production/87c23bf337ec4618cfcc0cc4b2b7c4858b4f5a17-1000x313.png]
DNA sequencing and other biological techniques will continue to increase the
number and complexity of genomic data sets.
Source:

But it’s not just about data volume. Massive computing power has enabled
researchers from the University of Illinois to develop a that metabolizes and
grows like a living cell. Cell simulation provides insights into the physical
and chemical processes that form the foundation of living cells, where
fundamental behaviors emerge not because they were programmed in, but because
the model contained the correct parameters and mechanisms.

Life Sciences is going through an accelerated transformation, and Machine
Learning (ML) is responsible for it. On top of that, during the Covid-19
pandemic Life Sciences companies were forced to mobilize their resources to
respond quickly to public health demands, which caused a spike of new
computational methods and ways of thinking.


APPLIED MACHINE LEARNING IN LIFE SCIENCES

Massive data volumes plus improved computation have eased the path to ML models
that can solve new challenges in Life Sciences. From the big universe of
potential applications, some that deserve special attention are:

 * Improved diagnostics, since diagnosis is the most fundamental step in the
   treatment of any patient.
 * Drug discovery, as the biggest goal of the Life Sciences industry is to
   advance the research and innovation for new products and treatments.


IMPROVING DIAGNOSTICS WITH COMPUTER VISION

Computer Vision (CV) focuses on image and video understanding, involving object
detection, image classification, and segmentation. In Life Sciences, CV models
fed with medical imaging (e.g. MRI, X-rays, etc) can assist in the visualization
of cells, tissues and organs to enable a more accurate diagnosis, helping to
identify any issues or abnormalities.

There’s huge , since computed tomography (CT) scans and magnetic resonance
imaging (MRI) are capable of generating 3D image data, while digital microscopy
can generate terabytes of whole slide image (WSI) of tissue specimens.

One example is the UC San Diego Health, which applies CV models to quickly
through X-rays imagery, which are cheaper and faster than other methods. But
adding to these types of problems can increase the performance and of a
diagnostic approach that medical professionals can easily use as an auxiliary
tool. In CV, are often used as , allowing us to exploit pre-trained models like
VGG, AlexNet or ResNet.

Pretrained models
[https://cdn.sanity.io/images/vr8gru94/production/13b8b69586aa58367ad5fbb420567868d0a0db75-550x207.png]
In this example, three-types of pre-trained models (ResNet152, DenseNet121 and
ResNet18) act as feature extractors. Redefining a classifier for a new task and
applying an attention mechanism as a feature selector can improve accuracy over
other models.
Source:

Due to the need for large datasets to train and tune Deep Learning architectures
for CV which are not available for medical images, TL coupled with embeddings
can be used to achieve tasks that go from to .

Convolutional Neural Network
[https://cdn.sanity.io/images/vr8gru94/production/388f7bca602ed7b5aa0bdd20972923143f422cad-500x200.png]
A Convolutional Neural Network (CNN) component acts as a feature extractor that
takes a grid of patches as input, and encodes each patch as a fixed-length
vector representation (i.e. embedding).
Source:

To solve CV challenges, the has been to use TL with pre-trained convolutional
neural networks (CNNs) on natural images (e.g., ResNet), tuned on medical
images. Today, due to their powerful TL abilities, pre-trained (which are
self-attention-based models) are becoming standard models to improve results on
CV tasks.


DRUG DISCOVERY

Drug discovery is the process of finding new or existing molecules with specific
chemical properties for the treatment of diseases. Since this has traditionally
been an extremely long and expensive process, modern predictive models based on
ML have gained popularity for their potential to drastically reduce costs and
research times.

ML can be used the in the :

 * Discover structure patterns: to study the surface properties, molecular
   volumes or molecular interactions.
 * Identify behavior influences: to relate the orientation of the molecule to
   its characteristics.
 * Anticipate characteristics: to develop models capable of predicting the
   behavior of a molecule in accordance with its design.
 * Improve drug designs: to get better results and design better medicines while
   reducing costs.

This is what companies like Sanofi are doing in order to in the real world by
doing much of the analysis on a computer.

How do you represent molecules in the data space? From the , embedding methods
like have emerged as novel approaches to learn high-dimensional representations
of molecular substructures. Inspired by word embedding techniques known as
Word2Vec, Mol2Vec encodes molecules into a set of vectors that represent similar
substructures in proximity to one another in the vector space. In a (NLP)
analogous fashion, molecules are considered as sentences and substructures as
words.

Mol2vec vectors
[https://cdn.sanity.io/images/vr8gru94/production/535cb7959c49700b6d0cc5b5b78189d232136ab0-1000x671.png]
Mol2vec vectors of amino acids (bold arrows). These vectors were obtained by
summing the vectors of the Morgan substructures (small arrows) present in the
respective molecules (amino acids in the present example). The directions of the
vectors provide a visual representation of similarities. Magnitudes reflect
importance, i.e. more meaningful words.
Source:

But molecules can also be represented as graphs. Graphs are a ubiquitous data
structure, employed extensively within computer science and related fields.
Social networks, molecular graph structures, biological protein-protein
networks, recommender systems — all of these domains and many more can be
readily modeled as graphs, which capture interactions (i.e., edges) between
individual units (i.e., nodes).

Nodes and edges
[https://cdn.sanity.io/images/vr8gru94/production/e7cae2461a594d1c835c012ae094eb5fdcb6dbff-800x321.png]
The nodes can be described as the vertices that correspond to objects. The edges
can be referred to as the connections between objects.
Source:

Intuitively, one could imagine treating the atoms in a molecule as nodes and the
bonds as edges. Nodes, edges, subgraphs or entire graphs can be embedded into .
These low-dimensional embeddings can be viewed as encoding or projecting graph
information into a latent space, where geometric relations in this latent space
correspond to interactions in the original graph.

Molecular graphs
[https://cdn.sanity.io/images/vr8gru94/production/55830f8cb54950aba17f22a368c8c51d21d781c3-1000x738.png]
Embedding molecular graphs into low dimensional space to determine if they are
benign or toxic.
Source:

The idea behind using graph embeddings is to create insights that are not
directly evident by looking at the explicit relationships between nodes.


THE FUTURE

The data explosion and initiatives in Life Sciences have the potential to
reshape the future of the industry and of patient care, as we witness how ML
methods can do amazing things if you give them enough data. Just look at what
DeepMind announced only some weeks ago, known to science (over 200 million
structures in total), using its AI AlphaFold 2.

You can see one prediction Alpha Fold’s model created. In comparison to the time
it takes in the lab, this model is able to make a prediction in a mere half an
hour with 90% accuracy according to their statement.
Source:

But it’s both the volume and diversity of data that force us to rethink how to
solve problems in Life Sciences with ML. Life Sciences is demanding us to
integrate all sorts of different data types to reach better results, while
giving us a glimpse of what’s coming next for all industries: a multimodal
future.

Consider Electronic Health Records (EHRs), which offer an and are becoming more
and more widely used by healthcare providers around the world. EHRs can include
data that go from images, clinical notes, medication lists, vital signs, to
demographic information, which can provide deep insights of a patient’s
condition if integrated in an effective manner.

Efforts to integrate these data types are already ongoing, and multimodal ML
models trained on numerous types of data could help health professionals to
screen patients at risk of developing diseases like cancer more accurately. This
is what is researching, by training ML models with microscopic views of cell
tissues from whole-slide images (WSIs) and text-based genomics data. Just
imagine what other challenges can be faced when integrating image, sequential,
text, 3D, graph and other types of data into the same information space.

Combining data
[https://cdn.sanity.io/images/vr8gru94/production/ebcf81edcaebe91a7660df51f95f323a56db3c78-800x198.png]
Combining data collected from both home (left) and clinical settings (right), or
combining predictive models built at home and in the clinic, has the potential
to lead to comprehensive and integrated models that support personalized health
management. Comprehensive models are more likely to perform well as they
incorporate more information about an individual, and these models have the
potential to be applied in the home, clinic, or wherever an individual may be.
Source:

ML will transform Life Sciences, and allow us to dream big in solving some of
the most transcendental challenges for humanity, like eliminating aging or
hyper-personalized healthcare. This is such a powerful Artificial Intelligence
(AI) application, that the UK government has established it as a , and people
like (the creator of the cryptocurrency Ethereum) and (founder of Amazon)
invested part of their fortune in this idea. From to in developing regions,
applied ML in Life Sciences can deeply change our lives.

Share via:


FURTHER READING


Author
[/_next/image/?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fvr8gru94%2Fproduction%2Fa800979e65dc4e374b59c6010e78b8851708e013-475x512.png&w=3840&q=100]

Diego Lopez Yse

Data Scientist

--------------------------------------------------------------------------------

Jump to section
 * 
 * 

Share via:


Product

Solutions

Resources

Company

Legal


© Pinecone Systems, Inc. | San Francisco, CA

Pinecone is a registered trademark of Pinecone Systems, Inc.

[/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fpopup-bg.197eeb2c.png&w=3840&q=100]


INTRODUCING — PINECONE SERVERLESS

Build knowledgeable AI at up to 50x lower cost. No need to manage
infrastructure. Get started with $100 in usage credits.



DON'T MISS THE NEXT ONE...



Get an email the next time we publish an article about machine learning and
similarity search.

Get Updates