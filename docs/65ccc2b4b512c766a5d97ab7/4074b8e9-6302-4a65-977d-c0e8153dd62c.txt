Opens in a new window Opens an external website Opens an external website in a
new window
<!---->Close this dialog<!---->
This website utilizes technologies such as cookies to enable essential site
functionality, as well as for analytics, personalization, and targeted
advertising purposes. To learn more, view the following link:



<!---->Close Cookie Preferences<!---->


Product
Solutions
Resources
Company



VECTOR EMBEDDINGS FOR DEVELOPERS: THE BASICS

Jun 30, 2023

Author
[/_next/image/?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fvr8gru94%2Fproduction%2F9f722be20c8f1800c6a43e8bc87256078071d90d-512x512.webp&w=3840&q=100]

Developer Advocate

--------------------------------------------------------------------------------

Jump to section

--------------------------------------------------------------------------------

You might not know it yet, but vector embeddings are everywhere. They are the
building blocks of many machine learning and deep learning algorithms used by
applications ranging from search to AI assistants. If you’re considering
building your own application in this space, you will likely run into vector
embeddings at some point. In this post, we’ll try to get a basic intuition for
what vector embeddings are and how they can be used.


WHAT PROBLEM ARE WE TRYING TO SOLVE?

When you build a traditional application, your data structures are represented
as objects that probably come from a database. These objects have properties (or
columns in a database) that are relevant to the application you’re building.

Over time, the number of properties of these objects grows — to the point where
you may need to be more intentional about which properties you need to complete
a given task. You may even end up creating specialized representations of these
objects to solve particular tasks without paying the overhead of having to
process very “fat” objects. This process is known as feature engineering — you
optimize your application by picking only the essential features relevant to the
task at hand.

When you deal with unstructured data, you will have to go through this same
feature engineering process. However, unstructured data is likely to have many
more pertinent features, and performing manual feature engineering is bound to
be untenable.

In those cases, we can use vector embeddings as a form of automatic feature
engineering. Instead of manually picking the required features from our data, we
apply a pre-trained machine learning model that will produce a representation of
this data that is more compact while preserving what’s meaningful about the
data.


WHAT ARE VECTOR EMBEDDINGS?

Before we delve into what vector embeddings are, let’s talk about vectors. A
vector is a mathematical structure with a size and a direction. For example, we
can think of the vector as a point in space, with the “direction” being an arrow
from (0,0,0) to that point in the vector space.

Vector diagram
[https://cdn.sanity.io/images/vr8gru94/production/c6a923ebc992a3622134ebd95e9992b269299918-214x216.png]


As developers, it might be easier to think of a vector as an array containing
numerical values. For example:

vector = [0,-2,...4]



When we look at a bunch of vectors in one space, we can say that some are closer
to one another, while others are far apart. Some vectors can seem to cluster
together, while others could be sparsely distributed in the space.

Vector distance diagram
[https://cdn.sanity.io/images/vr8gru94/production/f3b48ac3b18dec0f97fbcf6eb2a294a2993eb4b1-214x216.png]


We’ll soon explore how these relationships between vectors can be useful.

Vectors are an ideal data structure for machine learning algorithms — modern
CPUs and GPUs are optimized to perform the mathematical operations needed to
process them. But our data is rarely represented as vectors. This is where
vector embedding comes into play. It’s a technique that allows us to take
virtually any data type and represent it as vectors.

But it isn’t as simple as just turning data into vectors. We want to ensure that
we can perform tasks on this transformed data without losing the data’s original
meaning. For example, if we want to compare two sentences — we don’t want just
to compare the words they contain but rather whether or not they mean the same
thing. To preserve the data’s meaning, we need to understand how to produce
vectors where relationships between the vectors make sense.

To do this, we need what’s known as an embedding model. Many modern embedding
models are built by passing a large amount of labeled data to a neural network.
You might have heard of neural networks before — they are also a popular tool
used to solve all sorts of complex problems. In very simple terms, neural
networks are made of layers of nodes connected by functions. We then train these
neural networks to perform all sorts of tasks.

We train neural networks by applying supervised learning — feeding the network a
large set of training data made of pairs of inputs and labeled outputs.
Alternatively, we can apply self-supervised or unsupervised learning either of
which doesn’t require labeled outputs. These values are transformed with each
layer of network activations and operations. With every iteration of training,
the neural network modifies the activations in each layer. Eventually, it can
predict what an output label should be for a given input — even if it hasn’t
seen that particular input before.

The embedding model is basically this neural network with the last layer
removed. Instead of getting a specific labeled value for an input, we get a
vector embedding.

A great example of an embedding model is the popular , which is regularly used
for a wide variety of text-based tasks. Let’s take a look at a visualization
produced by TensorFlow’s tool, which makes it easy to visualize embeddings.

Embedding Visualization
[https://cdn.sanity.io/images/vr8gru94/production/e66cb043c83cc1d2f2d1b8fabc8fe5f06970afef-1300x1040.png]


While this visualization represents only three dimensions of the embeddings, it
can help us understand how the embedding model works. There are multiple data
points highlighted in the visualization, each representing a vector embedding
for a word. As the name suggests, word2vec embeds words. Words that appear close
to one another are semantically similar, while far-apart words have different
semantic meanings.

Once trained, an embedding model can transform our raw data into vector
embeddings. That means it knows where to place new data points in the vector
space.

Embedding Process
[https://cdn.sanity.io/images/vr8gru94/production/12bb49165edf8c020b3ae6cf94d49ee12be3c106-755x212.png]


As we saw with word2vec, within the context of the model, vectors that are close
together have a contextual similarity, whereas far-apart vectors are different
from one another. That’s what gives our vector meaning — its relationship with
other vectors in the vector space depends on how the embedding model
“understands” the domain it was trained on.


WHAT CAN I DO WITH VECTOR EMBEDDINGS?

Vector embeddings are an incredibly versatile tool and can be applied in many
domains. Generally speaking, an application would use a vector embedding as its
query and produce other vector embeddings which are similar to it, with their
corresponding values. The difference between applications of each domain is the
significance of this similarity.

Here are some examples:

 * Semantic Search - search engines traditionally work by searching for overlaps
   of keywords. By leveraging vector embeddings, can go beyond keyword matching
   and deliver based on the query’s semantic meaning.
 * Question-answering applications - by training an embedding model with pairs
   of questions and corresponding answers, we can create an application that
   would that have not been seen before.
 * Image search - vector embeddings are perfectly suited to serve as the basis
   for image retrieval tasks. There are multiple off-the-shelf models, such as ,
   ResNet, and more. Different models handle different types of tasks like ,
   object detection, and many more.
 * Audio search - by converting the audio into a set of activations (an audio
   spectrogram), we produce vector embeddings that can be used for .
 * Recommender Systems - we can create embeddings out of structured data that
   correlate to different entities such as , articles, etc. In most cases, you’d
   have to create your own embedding model since it would be specific to your
   particular application. Sometimes this can be combined with unstructured
   embedding methods when images or text descriptions are found.
 * Anomaly detection - We can create embeddings for anomaly detection using
   large data sets of labeled sensor information that .

Vector embeddings are incredibly powerful, and this is by no means an exhaustive
list — head to our to go deeper. You can also read more about the basics of to
see how can help you wrangle vector embeddings.

Share via:


FURTHER READING


Author
[/_next/image/?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fvr8gru94%2Fproduction%2F9f722be20c8f1800c6a43e8bc87256078071d90d-512x512.webp&w=3840&q=100]

Developer Advocate

--------------------------------------------------------------------------------

Jump to section
 * 
 * 
 * 

Share via:


Product

Solutions

Resources

Company

Legal


© Pinecone Systems, Inc. | San Francisco, CA

Pinecone is a registered trademark of Pinecone Systems, Inc.

[/_next/image/?url=%2F_next%2Fstatic%2Fmedia%2Fpopup-bg.197eeb2c.png&w=3840&q=100]


INTRODUCING — PINECONE SERVERLESS

Build knowledgeable AI at up to 50x lower cost. No need to manage
infrastructure. Get started with $100 in usage credits.



DON'T MISS THE NEXT ONE...



Get an email the next time we publish an article about machine learning and
similarity search.

Get Updates